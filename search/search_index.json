{"config":{"lang":["pt"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Identifica\u00e7\u00e3o de PII - Hackathon CGDF","text":"<p>Bem-vindo \u00e0 documenta\u00e7\u00e3o oficial da solu\u00e7\u00e3o desenvolvida para o 1\u00ba Hackathon em Controle Social: Desafio Participa DF.</p>"},{"location":"#contexto-do-projeto","title":"Contexto do Projeto","text":"<p>Este projeto foi concebido para a Categoria Acesso \u00e0 Informa\u00e7\u00e3o. O desafio proposto pela CGDF consiste em desenvolver modelos capazes de identificar automaticamente pedidos de acesso \u00e0 informa\u00e7\u00e3o que contenham dados pessoais, garantindo que manifesta\u00e7\u00f5es que deveriam ser restritas n\u00e3o sejam classificadas indevidamente como p\u00fablicas.</p> <p>Escopo de Dados Pessoais (Edital)</p> <p>De acordo com as diretrizes do edital para este Hackathon, o modelo foi configurado para identificar especificamente as seguintes entidades como dados pessoais restritos: RG, CPF, Nome, Telefone e E-mail.</p>"},{"location":"#tecnologias-utilizadas","title":"Tecnologias Utilizadas","text":"<ul> <li>Linguagem: Python 3.10+</li> <li>IA &amp; NLP: Microsoft Presidio, Spacy (pt_core_news_lg).</li> <li>LLM: DeepSeek para an\u00e1lise sem\u00e2ntica de contexto.</li> <li>Processamento: Pandas e TQDM para gest\u00e3o de grandes volumes de dados (batch).</li> </ul>"},{"location":"#contribuidores","title":"Contribuidores","text":"<sub>Danielle Soares</sub> <sub>Pedro Henrique Nunes</sub>"},{"location":"arquitetura/","title":"Arquitetura do Sistema","text":"<p>O sistema exp\u00f5e uma API REST como ponto de entrada. A partir do momento em que um texto \u00e9 enviado, a requisi\u00e7\u00e3o \u00e9 validada e rapidamente respondida com status HTTP de sucesso, evitando que o cliente fique bloqueado aguardando o processamento completo. Essa decis\u00e3o arquitetural reduz lat\u00eancia percebida e protege o sistema contra sobrecarga direta na camada s\u00edncrona.</p> <p>Ap\u00f3s o recebimento do texto, o conte\u00fado e seus metadados iniciais s\u00e3o persistidos diretamente no banco de dados, que atua como a principal fonte de verdade do sistema. Essa persist\u00eancia imediata garante rastreabilidade do processamento e permite que o fluxo ass\u00edncrono continue mesmo em cen\u00e1rios de falha parcial.</p> <p>Com os dados persistidos, um evento \u00e9 publicado em uma fila de mensagens, que pode ser implementada com RabbitMQ ou Kafka. A mensageria \u00e9 um elemento central da arquitetura, pois desacopla completamente a entrada do sistema do processamento pesado. Isso permite escalar consumidores de forma independente, absorver picos de carga e aplicar estrat\u00e9gias de retry sem impactar diretamente a API.</p> <p>O servi\u00e7o de processamento consome mensagens dessa fila de forma ass\u00edncrona. Esse componente \u00e9 respons\u00e1vel por executar a l\u00f3gica principal de classifica\u00e7\u00e3o, determinando se o texto cont\u00e9m ou n\u00e3o informa\u00e7\u00f5es sens\u00edveis. Ap\u00f3s a an\u00e1lise, o servi\u00e7o atualiza o status do registro no banco de dados, marcando-o como conclu\u00eddo ou com falha, al\u00e9m de persistir o resultado da classifica\u00e7\u00e3o. Esse servi\u00e7o \u00e9 stateless e projetado para escalar horizontalmente conforme a demanda.</p> <p>Uma vez que o processamento \u00e9 finalizado, um worker dispatcher entra em a\u00e7\u00e3o. Esse componente monitora o banco de dados por meio de polling e identifica registros que atingiram estados finais de processamento. Ao detectar essas condi\u00e7\u00f5es, o dispatcher \u00e9 respons\u00e1vel por notificar sistemas externos por meio de um webhook. Para garantir resili\u00eancia nessa integra\u00e7\u00e3o, a chamada externa passa por um circuito de circuit breaker, prevenindo falhas em cascata e protegendo o sistema contra indisponibilidades externas.</p> <p>Do ponto de vista operacional, essa arquitetura prioriza desacoplamento e toler\u00e2ncia a falhas. Mesmo que o servi\u00e7o externo esteja indispon\u00edvel ou o processamento sofra atrasos, a API continua respondendo corretamente e o sistema mant\u00e9m consist\u00eancia interna.</p> <p>Os testes de carga realizados com o k6 ajudam a evidenciar esse comportamento. Em um primeiro cen\u00e1rio, com baixa concorr\u00eancia, o sistema apresentou desempenho bastante eficiente. Foram executadas 100 itera\u00e7\u00f5es, todas bem-sucedidas, com lat\u00eancia end-to-end m\u00e9dia em torno de 560ms e tempo m\u00e9dio de resposta do POST de aproximadamente 28ms. O polling praticamente n\u00e3o ocorreu, com valor m\u00e9dio igual a 1, indicando que o processamento foi r\u00e1pido o suficiente para que o resultado estivesse dispon\u00edvel quase imediatamente. Um trecho representativo do output do k6 nesse cen\u00e1rio \u00e9:</p> <pre><code>TOTAL RESULTS \n\nchecks_total.......: 100     4.497343/s\nchecks_succeeded...: 100.00% 100 out of 100\nchecks_failed......: 0.00%   0 out of 100\n\nCUSTOM\ncompleted......................: 97     4.362423/s\nfailed.........................: 3      0.13492/s\nlatency_e2e....................: avg=560.48ms min=513ms    med=520ms    max=900ms    p(90)=664ms    p(95)=720.39ms\nlatency_post...................: avg=28.68ms  min=6ms      med=11ms     max=380ms    p(90)=60.9ms   p(95)=108.64ms\npoll_count.....................: avg=1        min=1        med=1        max=1        p(90)=1        p(95)=1       \n\nHTTP\nhttp_req_duration..............: avg=23.81ms  min=4.47ms   med=8.03ms   max=362.09ms p(90)=64.58ms  p(95)=110.94ms\n    { expected_response:true }...: avg=23.81ms  min=4.47ms   med=8.03ms   max=362.09ms p(90)=64.58ms  p(95)=110.94ms\nhttp_req_failed................: 0.00%  0 out of 313\nhttp_reqs......................: 313    14.076684/s\n\nEXECUTION\niteration_duration.............: avg=1.15s    min=513.59ms med=521.13ms max=20.33s   p(90)=709.82ms p(95)=876.75ms\niterations.....................: 100    4.497343/s\nvus............................: 3      min=3        max=11\nvus_max........................: 50     min=50       max=50\n\nNETWORK\ndata_received..................: 1.5 MB 66 kB/s\ndata_sent......................: 325 kB 15 kB/s\n</code></pre> <p>Esse resultado demonstra que, sob carga controlada, o sistema se comporta de forma extremamente est\u00e1vel, com baixa lat\u00eancia e alto throughput.</p> <p>No segundo cen\u00e1rio, o sistema foi submetido a alta concorr\u00eancia, alcan\u00e7ando at\u00e9 200 usu\u00e1rios virtuais simult\u00e2neos. Nesse contexto, embora nenhuma falha HTTP tenha sido registrada, a lat\u00eancia end-to-end aumentou significativamente, atingindo uma m\u00e9dia de aproximadamente 12 segundos. Esse aumento est\u00e1 diretamente relacionado ao crescimento da fila e ao tempo de espera at\u00e9 que o processamento ass\u00edncrono fosse conclu\u00eddo. O polling m\u00e9dio subiu para cerca de 21 tentativas, evidenciando que o dispatcher precisou consultar o banco diversas vezes at\u00e9 encontrar o status final do processamento. Um recorte do output do k6 nesse cen\u00e1rio ilustra bem esse comportamento:</p> <pre><code>TOTAL RESULTS \n\nchecks_total.......: 301     10.543627/s\nchecks_succeeded...: 100.00% 301 out of 301\nchecks_failed......: 0.00%   0 out of 301\n\nCUSTOM\ncompleted......................: 301    10.543627/s\nlatency_e2e....................: avg=12.11s    min=539ms    med=13.17s  max=19.45s   p(90)=18.96s   p(95)=19.15s  \nlatency_post...................: avg=67.11ms   min=8ms      med=19ms    max=703ms    p(90)=183ms    p(95)=253ms   \npoll_count.....................: avg=21.385382 min=1        med=23      max=35       p(90)=34       p(95)=34      \n\nHTTP\nhttp_req_duration..............: avg=60.31ms   min=3.94ms   med=38.32ms max=693.55ms p(90)=131.11ms p(95)=145.93ms\n    { expected_response:true }...: avg=60.31ms   min=3.94ms   med=38.32ms max=693.55ms p(90)=131.11ms p(95)=145.93ms\nhttp_req_failed................: 0.00%  0 out of 6738\nhttp_reqs......................: 6738   236.023123/s\n\nEXECUTION\ndropped_iterations.............: 699    24.485035/s\niteration_duration.............: avg=12.11s    min=539.89ms med=13.17s  max=19.45s   p(90)=18.96s   p(95)=19.15s  \niterations.....................: 301    10.543627/s\nvus............................: 11     min=11        max=200\nvus_max........................: 200    min=100       max=200\n\nNETWORK\ndata_received..................: 23 MB  792 kB/s\ndata_sent......................: 1.7 MB 59 kB/s\n</code></pre> <p>Apesar do aumento da lat\u00eancia total, o tempo de resposta da API permaneceu baixo, o que confirma a efic\u00e1cia da estrat\u00e9gia de processamento ass\u00edncrono. A mensageria conseguiu absorver o pico de requisi\u00e7\u00f5es sem perda de dados, e o sistema manteve consist\u00eancia e confiabilidade durante todo o teste.</p> <p>De forma geral, a arquitetura demonstra-se robusta e bem alinhada para cen\u00e1rios reais de produ\u00e7\u00e3o, especialmente quando a prioridade \u00e9 confiabilidade e escalabilidade, mesmo que isso implique maior lat\u00eancia end-to-end em situa\u00e7\u00f5es de alta carga. Como evolu\u00e7\u00e3o natural, podem ser consideradas melhorias como redu\u00e7\u00e3o da depend\u00eancia de polling, ado\u00e7\u00e3o de eventos de conclus\u00e3o, ajustes no paralelismo do servi\u00e7o de processamento e implementa\u00e7\u00e3o de filas de dead letter para tratamento de falhas.</p> <p>Conclui-se que o sistema est\u00e1 tecnicamente bem fundamentado, com decis\u00f5es arquiteturais coerentes e sustentadas pelos resultados observados nos testes de carga, sendo plenamente capaz de operar em ambientes de alto volume com comportamento previs\u00edvel e resiliente.</p>"},{"location":"instalacao/","title":"Guia de Instala\u00e7\u00e3o do Sistema","text":"<p>Antes de iniciar, \u00e9 necess\u00e1rio garantir que o ambiente possua Docker e Docker Compose instalados. Recomenda-se Docker vers\u00e3o 20 ou superior e Docker Compose v2. N\u00e3o \u00e9 necess\u00e1rio instalar Python, PostgreSQL ou RabbitMQ localmente, pois todos esses componentes s\u00e3o executados em containers.</p> <p>O primeiro passo \u00e9 preparar o arquivo de vari\u00e1veis de ambiente. No reposit\u00f3rio do projeto existe um arquivo <code>.env.example</code>, que deve ser copiado para <code>.env</code>. Esse arquivo centraliza todas as configura\u00e7\u00f5es necess\u00e1rias para o funcionamento do sistema, incluindo credenciais de banco de dados, mensageria, integra\u00e7\u00e3o com webhook externo e, opcionalmente, configura\u00e7\u00f5es de LLM.</p> <p>As vari\u00e1veis relacionadas ao PostgreSQL permitem duas abordagens distintas. Caso voc\u00ea queira subir uma inst\u00e2ncia dedicada apenas para este sistema, basta manter as vari\u00e1veis <code>POSTGRES_USER</code>, <code>POSTGRES_PASSWORD</code> e <code>POSTGRES_DB</code> conforme o exemplo. A URL de conex\u00e3o (<code>DATABASE_URL</code>) j\u00e1 est\u00e1 preparada para apontar para o container do PostgreSQL definido no Docker Compose. Caso voc\u00ea j\u00e1 possua um banco externo, basta sobrescrever a vari\u00e1vel <code>DATABASE_URL</code> com a string de conex\u00e3o adequada, podendo inclusive remover o servi\u00e7o de PostgreSQL do compose se desejar.</p> <p>De forma semelhante, o RabbitMQ tamb\u00e9m pode ser utilizado de duas maneiras. Por padr\u00e3o, o Docker Compose sobe uma inst\u00e2ncia local do RabbitMQ, utilizando as credenciais definidas em <code>RABBIT_USER</code> e <code>RABBIT_PASSWORD</code>. A vari\u00e1vel <code>RABBIT_URL</code> aponta automaticamente para esse container. Em ambientes onde j\u00e1 existe um broker dispon\u00edvel, basta alterar essa URL para o endere\u00e7o externo e, se necess\u00e1rio, remover o servi\u00e7o <code>rabbitmq</code> do compose.</p> <p>Outro ponto importante do arquivo <code>.env</code> \u00e9 a configura\u00e7\u00e3o do webhook. A vari\u00e1vel <code>WEBHOOK_URL</code> define para onde o dispatcher enviar\u00e1 os resultados do processamento. Em ambiente local, \u00e9 comum utilizar <code>http://host.docker.internal</code> para alcan\u00e7ar um servi\u00e7o rodando fora do Docker, como um servidor Express em Node.js. Tamb\u00e9m \u00e9 poss\u00edvel configurar um segredo opcional para o webhook, que ser\u00e1 enviado como header HTTP, aumentando a seguran\u00e7a da integra\u00e7\u00e3o.</p> <p>O sistema tamb\u00e9m suporta, de forma opcional, um fallback para LLM. Quando habilitado, caso o mecanismo principal de detec\u00e7\u00e3o n\u00e3o encontre dados sens\u00edveis, uma LLM pode ser utilizada como segunda camada de an\u00e1lise. Essa funcionalidade \u00e9 controlada pela vari\u00e1vel <code>LLM_FALLBACK</code>. Caso seja ativada, \u00e9 necess\u00e1rio informar o modelo, a URL base da API e a chave de autentica\u00e7\u00e3o.</p> <p>Com o arquivo <code>.env</code> devidamente configurado, o pr\u00f3ximo passo \u00e9 subir os containers. A partir da raiz do projeto, basta executar o comando:</p> <pre><code>docker compose up --build\n</code></pre> <p>Esse comando ir\u00e1 construir as imagens da API, do worker e do dispatcher, al\u00e9m de iniciar os containers do PostgreSQL e do RabbitMQ. Durante a primeira execu\u00e7\u00e3o, o processo pode levar alguns minutos devido ao build das imagens e \u00e0 inicializa\u00e7\u00e3o dos servi\u00e7os.</p> <p>Ap\u00f3s a subida dos containers, a API REST ficar\u00e1 dispon\u00edvel, por padr\u00e3o, na porta 8000 do host. Nesse ponto, j\u00e1 \u00e9 poss\u00edvel enviar requisi\u00e7\u00f5es HTTP para o endpoint de cria\u00e7\u00e3o de processamento, enviando um texto para an\u00e1lise. A resposta da API ser\u00e1 imediata, retornando um status de sucesso, enquanto o processamento ocorrer\u00e1 de forma ass\u00edncrona em background.</p> <p>Para fins de observabilidade e depura\u00e7\u00e3o, o RabbitMQ Management Plugin fica acess\u00edvel na porta 15672, permitindo acompanhar filas, consumidores e taxa de mensagens. Os logs de cada servi\u00e7o podem ser acompanhados diretamente pelo Docker Compose, facilitando a identifica\u00e7\u00e3o de problemas durante a instala\u00e7\u00e3o ou execu\u00e7\u00e3o.</p> <p>Caso seja necess\u00e1rio interromper o sistema, basta utilizar <code>docker compose down</code>. Os dados do PostgreSQL e do RabbitMQ s\u00e3o persistidos em volumes Docker, o que garante que informa\u00e7\u00f5es n\u00e3o sejam perdidas entre reinicializa\u00e7\u00f5es, a menos que os volumes sejam removidos explicitamente.</p>"},{"location":"raciocinio/","title":"Racioc\u00ednio T\u00e9cnico","text":"<p>Esta p\u00e1gina detalha a fundamenta\u00e7\u00e3o l\u00f3gica e as escolhas arquiteturais que sustentam a robustez da solu\u00e7\u00e3o de detec\u00e7\u00e3o de PII (Personally Identifiable Information).</p>"},{"location":"raciocinio/#1-objetivo","title":"1. Objetivo","text":"<p>Identificar automaticamente pedidos de acesso \u00e0 informa\u00e7\u00e3o que cont\u00eam exposi\u00e7\u00e3o de dados pessoais \u2014 especificamente: Nome, CPF, RG, Telefone e E-mail \u2014 para impedir a publica\u00e7\u00e3o indevida de manifesta\u00e7\u00f5es sens\u00edveis.</p>"},{"location":"raciocinio/#2-o-problema-central","title":"2. O Problema Central","text":"<p>O processamento de manifesta\u00e7\u00f5es p\u00fablicas enfrenta o desafio do volume e da variabilidade de formatos. A solu\u00e7\u00e3o precisa equilibrar duas m\u00e9tricas fundamentais:</p> <ul> <li>Precis\u00e3o: N\u00e3o bloquear textos leg\u00edtimos/p\u00fablicos por erro do modelo.</li> <li>Sensibilidade (Recall): N\u00e3o permitir o vazamento de nenhum dado pessoal real.</li> </ul>"},{"location":"raciocinio/#3-logica-do-fluxo-de-dados","title":"3. L\u00f3gica do Fluxo de Dados","text":"<p>A solu\u00e7\u00e3o foi desenhada para ser escal\u00e1vel, utilizando um processamento ass\u00edncrono:</p> <ol> <li>Entrada: As mensagens com texto entram em uma fila de processamento (RabbitMQ).</li> <li>Consumo: O Worker (<code>app/services/worker.py</code>) consome a fila e dispara o m\u00e9todo <code>analyze_text</code>.</li> <li>An\u00e1lise H\u00edbrida (<code>analyze_text</code>):</li> <li>Camada 1 (PresidioScanner): Executa detec\u00e7\u00e3o baseada em padr\u00f5es e reconhecedores customizados.</li> <li>Camada 2 (LLMScanner - Fallback): Se a primeira camada for inconclusiva, uma LLM com prompt restrito decide entre <code>PRIVATE</code> ou <code>PUBLIC</code>.</li> <li>Sa\u00edda: Os resultados s\u00e3o gravados e despachados via webhook, contando com mecanismos de retry e circuit-breaker.</li> </ol>"},{"location":"raciocinio/#4-diferenciais-estrategicos","title":"4. Diferenciais Estrat\u00e9gicos","text":""},{"location":"raciocinio/#validacao-de-documentos-reais-cpfcnpj","title":"Valida\u00e7\u00e3o de Documentos Reais (CPF/CNPJ)","text":"<p>Diferente de solu\u00e7\u00f5es baseadas apenas em Regex, nosso <code>PresidioScanner</code> integra reconhecedores customizados que utilizam a biblioteca <code>validate_docbr</code>.</p> <ul> <li>CPFs V\u00e1lidos: Somente sequ\u00eancias num\u00e9ricas que passam no teste do d\u00edgito verificador s\u00e3o marcadas como PII.</li> <li>CPFs Inv\u00e1lidos: N\u00fameros aleat\u00f3rios que n\u00e3o correspondem a documentos reais s\u00e3o ignorados, reduzindo drasticamente os Falsos Positivos.</li> </ul>"},{"location":"raciocinio/#o-papel-da-llm-restrita","title":"O Papel da LLM Restrita","text":"<p>A LLM entra em cena para capturar exposi\u00e7\u00f5es que n\u00e3o seguem formatos r\u00edgidos, como:</p> <ul> <li>Nomes completos em contextos variados.</li> <li>Endere\u00e7os e refer\u00eancias pessoais impl\u00edcitas.</li> </ul> <p>Seguran\u00e7a do Prompt: O modelo responde <code>Y [TIPO]</code> ou <code>N</code>, minimizando alucina\u00e7\u00f5es e garantindo uma decis\u00e3o bin\u00e1ria clara.</p>"},{"location":"raciocinio/#5-riscos-e-mitigacoes","title":"5. Riscos e Mitiga\u00e7\u00f5es","text":"Risco Estrat\u00e9gia de Mitiga\u00e7\u00e3o Falsos Positivos (Regex) Valida\u00e7\u00e3o matem\u00e1tica de documentos e an\u00e1lise de palavras-chave contextuais. Falsos Negativos (LLM) Prompt r\u00edgido e enviesado para a seguran\u00e7a (na d\u00favida, classifica como <code>PRIVATE</code>). Indisponibilidade de API Sistema de logs de auditoria e fila de retentativa autom\u00e1tica."}]}